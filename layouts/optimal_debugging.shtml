<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title :text="$site.title"></title>
    <link rel="stylesheet" type="text/css" href="$site.asset('normalize.css').link()">
    <link rel="stylesheet" type="text/css" href="$site.asset('style.css').link()">
  </head>
  <body>
    <div class="home_page">
      <div class='static_grid'>
          <div class='static_double_column1'>
            <h1><span class="reset_a"><a href="/">Jans Website.</a></span> <span class="reset_a"><a href="/articles/about/">About.</a></span></h1>
          </div>
          <div class='static_double_column2'>
            <h2 :text="$page.title"></h2>
          </div>
          <div class='static_double_column3'>
            <div :html="$page.contentSection('intro')"></div>
            <div :html="$page.contentSection('theory')"></div>
            <div :html="$page.contentSection('practice')"></div>
            <!--<div :html="$page.content()"></div>-->
            <ol>
              <li> <a id ="hardware_problems"><b>Hard(ware) problems</b></a>
                <a href="https://interrupt.memfault.com/blog/schematic-review-checklist">
                Hardware design reviews</a>
                with extensive focus on core components
                (power, battery, periphery, busses, memory/flash and debug/test infrastructure)
                to enable debugging and component tests against product and assembling defects
                are fundamental for software debugging under assumption that computing unit(s)
                and memory unit(s) can be trusted to work reliable enough.
                Depending on goals, time channel analysis, formal methods to rule out logic
                errors and fuzzing against bad temporal behavior (for example during speculative execution)
                are common methods besides various testing strategies based on statistical analysis.
              </li>
              <li> <a id ="platform_problems"><b>Kernel and platform problems</b></a>
                The managing environment the code is running on can vary a lot.
                As example, the typical four phases of the Linux boot process
                (system startup, bootloader stage, kernel stage, and init process)
                have each their own debugging infrastructure and methods.
                Generally, working with (introspection-restricted) platforms requires
                1. reverse engineering and "trying to find info" and/or 2. "use some tracing
                tool" and 3. for open source "adjust the source and stare at kernel
                dumps/use debugger".
                Kernels are rarely designed for tracing, recording, formal
                verification due to internal complexity and virtualisation is slow and
                hides many classes of synchronization bugs.
                Due to being complex, moving targets, having no library design, having design flaws
                and many performance tradeoffs, Kernels are hard to fuzz test.
                <br>
                Non-micro kernels use the process as fundamental abstraction model,
                but no widely used Kernel has a formal process group model.
                Since there is no api to communicate from child to parent
                process initialization status and since signaling is racy,
                testing process groups is error-prone and a reliable testing
                setup is complex. Race conditions during read and write access
                to kernel objects like shared memory or file access (flush
                semantics) are the most common problems besides general
                reliance on any on timing of actions without handling the
                timeout path or resource over-saturation path (for example on
                high system load).
              </li>
              <li> <a id ="detectable_ub"><b>Detectable Undefined Behavior</b></a>
                <code>clang -Werror -Weverything -fsanitize="undefined,type"</code>, <code>zig -OReleaseSafe</code>, <code>zig -ODebug</code>
              </li>
              <li> <a id ="undetectable_ub"><b>Undetectable Undefined Behavior</b></a>
                Staring at source code, backend intermediate representation like LLVM
                IR and reducing the problem or resulting assembly. Unfortunately the
                backend optimizers like LLVM do not offer frontend language writers
                debug APIs and related tooling due to not being designed for that
                purpose, so one has to manually invoke the optimizations to reproduce
                the problem. A bespoke debug api would allow recording, replaying and
                tracing IR of each optimization step, ideally via reversal computing
                for optimal performance.
                Getting unoptimized LLVM IR via <code>zig --verbose-llvm-ir test.zig</code>
                (so far without an option to store LTO artifacts)
                and <code>clang -O3 -Xclang -disable-llvm-optzns -emit-llvm -S test.c</code>
                with (if needed) LTO artifact storing via <code>-plugin-opt=save-temps</code>.
                Getting optimized LLVM IR works via <code>clang -O3 -emit-llvm -S test.c</code>
                and <code>zig -femit-llvm-ir test.zig</code>.
              </li>
              <li> <a id ="miscomplations"><b>Miscompilations</b></a>
                Tools like Miri or Cerberus run the program in an interpreter,
                but may not cover all possible program semantics due to ambiguity
                and may not be feasible, so the only good chance is to reduce it
                as in <b>Undetectable Undefined Behavior</b>.
              </li>
              <li> <a id ="memory_problems"><b>Memory problems</b></a>
                <ol>
                  <li>Out-of-bounds (OOB) <code>clang -fsanitize=address</code>, <code>zig -ODebug/-OReleaseSafe</code></li>
                  <li>Null pointer dereference <code>clang -fsanitize=address</code>, <code>zig -ODebug/-OReleaseSafe</code></li>
                  <li>Type confusion <code>clang -fsanitize="address,undefined</code>, <code>zig -ODebug/-OReleaseSafe</code></li>
                  <li>Integer overflow <code>clang -fsanitize=undefined</code>, <code>zig -ODebug/-OReleaseSafe</code></li>
                  <li>Use after free <code>clang -fsanitize=address</code>, Zig allocator configuration</li>
                  <li>Invalid stack access <code>clang -fsanitize=address</code> and <code>ASAN_OPTIONS=detect_stack_use_after_return=1</code>
                  with 1.3-2x runtime and 11MB fake stack per thread, unimplemented in Zig.
                  </li>
                  <li>Usage of uninitialized memory (UUM) <code>clang -fsanitize=memory</code>,
                  unimplemented in Zig for partial initialization
                  (implementation only checks against any initialization, if
                  value is used in branch and only if memory is not coerced to
                  different types).
                  </li>
                  <li>Data races can be sanitized in Clang and Zig via <code>-fsanitize=thread</code>, but Zig offers no
                  annotation for "intentionally racy reads and writes" via <code>__attribute__((no_sanitize("thread")))</code>.
                  </li>
                  <li>Illegal aliasing can only be checked for typed aliasing with <code>clang -fsanitize=type</code>,
                  unimplemented in Zig.
                  </li>
                  <li>
                    Stack overflow from recursions or during the call chain of the program.
                    TODO list tooling to over-approximate stack usage upfront.
                    TODO list tooling to measure stack usage.
                  </li>
                </ol>
              </li>
              <li> <a id ="resource_leaks"><b>Resource leaks (freestanding/kernel)</b></a>
                Only process-based resources are considered here, which are accessible by the process as
                <ol>
                  <li>memory (stack is covered in <b>Memory problems</b>, heap)</li>
                  <li>handles/file descriptors</li>
                  <li>child processes (without ownership delegation)</li>
                </ol>
                There may be an association between 2. handles/file descriptors and 3. child processes
                (ie pidfd/GetProcessId, process group handles etc) xor 1. memory (ie on usage of mmap)
                or there may be none. There exists no tooling to check for point 3 and explaining the process group model
                with edge cases would make this article too long.
                <br>
                1. Automatic tools for memory leak detection are Valgrind MassIf (does not work on Windows) or using custom
                allocators with such functionality (or any of below for checking/proviling/tracing).
                Posix systems have for memory profiling Valgrind MassIf (<code>valgrind --tool=massif prog; ms_print massif.out.12345</code>),
                for memory checks Valgrind MemCheck (<code>valgrind --leak-check=full --show-leak-kinds=all --track-origins=yes --verbose prog</code>),
                for memory analysis at runtime <code>gdb</code> with <code>pwndbg</code> (for example using <code>vmmap</code>)
                or memory analysis after runtime using coredumps, meaning <code>gcore -o $TMPDIR/process $PID</code>,
                <code>cat /proc/$pid/smaps > $TMPDIR/TimeMemAction.txt</code> or
                <code>gdb -p $pid; dump memory memory.dump 0xSTART 0xEND; hexdump -C memory.dump</code>.
                Windows systems have for memory profiling VMMap (graphical), for memory checks
                but there is also  with a bunch of tooling
                Windows has for memory profiling VMMap and RAMMap, DrMemory as graphical tools, for memory leaks UMDH
                <code>gflags /i prog.exe +ust; $Env=_NT_EXECUTABLE_IMAGE_PATH="url_ms_sym_server"; umdh -p:$PID -f:b4leak.log; umdh b4leak.log afterleak.log > res.diff</code>,
                DrMemory, for memory analysis at runtime Visual Studio (Code) with "Memory Usage"
                and analysis after runtime with windbg
                <code>gflags /i prog.exe +ust; WinDbgX.exe prog.exe; .dump /ma b4leak.dmp;</code>
                <code>.opendump leak.dmp; f5; ||1s; ||.; !heap -s;</code>
                <code>!heap -h HANDLE; !heap -p -a ADDRESS; !heap -flt s SIZE</code> (find stack to allocation).
                <br>
                File descriptor/handle leaks can be automatically detected on Posix with Valgrind <code>valgrind --track-fds=yes prog</code>
                and on Windows with manually checking Handle, ProcessExplorer, ETW traces or automatically with proprietary solutions.
                <br>
                Examples for more direct access and control are on many Poxis systems
                <code>/proc/PID_OF_PROCESS</code>, on Windows <code>NtQuerySystemInformation</code>
                with <code>SYSTEM_HANDLE_INFORMATION</code> and <code>SYSTEM_HANDLE_TABLE_ENTRY_INFO</code>,
                on BSDs <code>sysctl</code>, <code>kvm</code>, <code>procmap</code> and there exist various other
                kernel specific trace options.
              </li>
              <li> <a id ="freezes"><b>Freezes (deadlocks, livelock, signal safety, unbounded loops etc)</b></a>
                LLVM has a not well-documented deadlock sanitizer option <code>TSAN_OPTIONS=detect_deadlocks=1:second_deadlock_stack=1</code>.
                <br>
                Livelock detection like infinitive loop detection would need
                annotation of progress and a step or time limit.
                So one good option is to do time or progress simulation in the testing build mode
                and do runtime-validation in intermediate steps.
                The same strategy can be applied to unbounded loops.
                <br>
                Signal safety requires fail-safe programming, especially on Posix,
                and would be another article also covering process group semantics.
                <code>ptrace(GETSIGINFO, ..)</code> , <code>WaitForDebugEvent</code> are options to trace signals
                besides kernel tracers like ktrace, dtrace or on Windows ETW, but usually it is simpler
                to reproduce the behavior in a debugger with simplified code.
              </li>
              <li> <a id ="perf_problems"><b>Performance problems</b></a>
                Extrapolation across multiple target hardware is unfeasible to do automatically.
                Simulation of CPU cache behavior of target hardware from any host hardware works via Valgrinds Cachegrind with
                Valgrinds Callgrind adding call graph information. Callgrind visualization exists for every platform.
                Accurate tracing on target hardware can be obtained based on hardware counters via Windows Event Tracing,
                Linux perf (perf_event_open), Darwin kperf (kpc_get_thread_counters), Event Trace for Windows (ETW) (StartTraceW)
                with Darwin having (yet) no cli api and gui.
                There are many approaches to do profiling of various program aspects
                with less accuracy and less space usage too long to list here.
              </li>
              <li> <a id ="logic_problems"><b>Logic problems</b></a>
                Logic problems of software systems can be described as problems
                related to incorrectly applied logic of how the code is solving the
                intended and follow-up problems ignoring hardware problems, kernel
                problems, different types of UB, miscompilations, memory problems,
                resource leaks, freezes and performance issues. <br>
                This typically includes
                <ol>
                  <li>software requirements or their handling, TODO better phrase requirements and specification?</li>
                  <li>(temporary) inconstency of state (relations)</li>
                  <li>incorrect math, for example not covering edge cases</li>
                  <li>incorrect modeling of external and internal state and synchronization</li>
                  <li>incorrect protocol handling</li>
                </ol>
                and is usually caused by
                <ol>
                  <li>incorrect constrains on the design, meaning how the different
                    parts should interact and work towards the goals for the use
                    cases</li>
                  <li>unclear, unspecified or incorrectly assumed hardware or software
                    guarantees by components</li>
                  <li>implementation oversights, unintended use cases, unfeasibility
                    of a general solution due to constrains like time, money etc</li>
                </ol>

                Those problems may be solved in the following ways
                <ol>
                  <li>
                    <b>Software requirements</b> typically depend on the hardware and software
                    platforms to specify the system type (how distributed,
                    event handling idea like state machine or query system), the
                    used protocols, platform requirements and provided functionality
                    with assurences (more rare are guarantees).
                    TODO rephrase
                    Those are typically written in UML, which is very inflexible
                    in contrast to an arbitrary graph for modeling system behavior.
                    Mermaid for UML looks nice, but has scalability issues on bigger drawings.
                    PlantUML does not look nice, but just works. draw.io for non-UML
                    is unnecessary complex, offers no data annotation and no sane
                    export format to reuse the graph in other tools (did not check
                    underlying representation) besides being not open source.
                    So in short terms, any tool with graph output will do, since
                    none is good, and for smaller models ascii/utf8 drawings work
                    fine.<br>
                    <b>Handling</b> means to track progress, for which time
                    feasibility and getting feasible design is essential.
                    TODO prototype, debugging and other things.
                  </li>
                  <li>(temporary) inconstency of state (relations) TODO</li>
                  <li>incorrect math, for example not covering edge cases TODO</li>
                  <li>incorrect modeling of external and internal state and synchronization TODO</li>
                  <li>incorrect protocol handling TODO</li>

                  <!--[1.Bugs related to functional behavior.]::-->
                  <!--[2.Bugs related to time behavior.]::-->
                  <!--[3.Internal and external system resources.]::-->

                </ol>

              </li>
            </ol>
            Ideally, only the system behavior and interactions with domain and
            use-case specific parts (<b>2. Kernel and platform problems</b>,
            <b>10. Logic problems</b>) need cognitive load from the programmer, whereas
            the other error classes should have standard approaches to isolate and eliminate.
            Unifying debug tooling simplifies usage for bigger developer productivity
            and exposing as library allows to automate this process.
          </div>
      </div>
    </div>
  </body>
</html>
